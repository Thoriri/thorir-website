---
title: Temporal Convolutional Networks
subtitle: A short introduction into how Temporal Convolutional Networks function

# Summary for listings and search engines
summary: An introduction into dilated causal convolutions, and a look into how Temporal Convolutional Networks (TCN) function.

# Link this post with a project
projects: []

# Date published
date: "2021-11-10T12:00:00Z"

# Date updated
lastmod: "2021-11-10T12:00:00Z"

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: false

# Featured image
# Place an image named `featured.jpg/png` in this page's folder and customize its options here.
image:
  caption: 'Residual blcok'
  focal_point: ""
  placement: 2
  preview_only: false

authors:
- admin

tags:
- Academic

categories:
---

Temporal Convolutional Networks (TCN) which are a variaton of Convolutional Neural Networks (CNN), recently have been used by deep learning practitioners to solve time series tasks with promising and successful outcomes as seen here [CITE]. I for one have employed TCNs for detecting Arythmia in ECG signals with great success. In this short post I want to explain how these networks work, how they differ from normal CNNs and take a look into the computational workload.

For sake of illusration I will explain all of these concepts here in 1D, but they also work in higher dimensions. First let us look at normal a CNN, let's assume that we have one layer, which has a kernel size of 3 and 1 filter. And let's assume that we have a input time series that looks like the one here below:
![Time series example](uploads/time_series.PNG "Example of time series")

When we then want to apply the 1D convolution to this input time series we do the following: We take our kernel size, which is 3, and slide it over the input time series to produce a output time series. Now how does this actually look like? Let's look at the first output of the output time series and see how that is produced,
![Showing how first sample of output time series is formed](uploads/conv.gif "Showing how first sample of output time seris is formed")
We then slide the kernel over the whole input time series and get the following output:
![Output time series](uploads/time_series_output.PNG "Output time series")
Now first thing we notice is that the output time series is not the same length as the input time series. This is because we do not do any padding, and we can calculate the output length by the following formula:
$$
T_{out} = T_{in} - (k-1)
$$
Where $k$ is the kernel size. TCNs work in a very similar way, with one addidional factor which is called dilation. Dilation is a way to increase the receptive field size of the network, with low cost to the number of operations needed. Let's look at a similar 1D convolution as before, but here we add the factor of $D = 2$ where $D$ stands for dilation. Note that in normal CNNs, dilation is fixed at $1$:
![Showing how the first sample of output time series is formed with dilation.](uploads/dilated_1.gif "First sample formed with dilation")
![Showing how the second sample of output time series is formed with dilation.](uploads/dilated_2.gif "Second sample formed with dilation")
As we can see adding the factor of dilation into our simple convolutional example radically changes the output time series:
![Output time series dilated](uploads/time_series_dilated_output.PNG "Output time series dilated")
Another thing that has changed is the size of our output series, as it is now not of length 6 but of length 4. This is since our formula before changes slightly with the addition of a dilation factor:
$$
T_{out} = T_{in} - (k-1)*D
$$
We can also see that this also holds true for normal convolutions as the dilation there is simply $D = 1$. One thing I noted here above was the 'Receptive Field Size (RFS)'. This is essentially how much of the time series each output node sees for computation. In this simple case we have here above the formula is simply:
$$
RFS = (k-1) * D + 1
$$
For the first case our RFS was simply $RFS = 3$ since $D =1$ and $k = 3$. Now for the dilated case this RFS increases to $RFS = 5$. Often when working with time series problems we want our network to be able output a time-series that is causal, meaning that when we calculate each time step we do not look into the future. To do so we need to add zero padding on the left hand side of the input time series. The size of the padding depends on both the kernel size and the dilation factor:
$$
Padding = (k-1) * D
$$
![Output time series dilated causal](uploads/time_series_padded_dilated_output.PNG "Output time series dilated causal")
Having this causal padding introduces an output time series that is the same length as our previous one simply because we know that $T_{in}^* = T_{in} + (k-1) * D$ and plugging that into the formula above gives us $T_{out} = T_{in}$. 

The last building block we need to introduce to be able to fully introduce the TCN network is the Residual block. 
![Residual Block](uploads/residual_block.png "Residual block")
The residual block consists of two dilated causal convolutions with normaliztion, non-linear activation and dropout inbetween. These residual blocks are then stacked on top of each other to build a network that has a receptive field size that fits the task at hand. Note that in these TCN networks the dilation factor is exponentially increased the more blocks you add to the network. The calculation of the receptive field size then changes a bit and becomes:
$$
RFS = 1 + (2^L -1)(k-1)*2
$$
Where $L$ stands for the number of residual blocks that are stacked on top of each other. 

Now let's look at a code example of a TCN tackling a time series task (Both in PyTorch and Tensorflow/Keras). 

We will focus on the FordA dataset from the [UCR/UEA
archive](https://www.cs.ucr.edu/~eamonn/time_series_data_2018/). We base the
data preprocessing of the one availale online from Keras, for further
information on why certain steps in the data preprocessing were done please take
a look at the source: See
[here](https://keras.io/examples/timeseries/timeseries_classification_from_scratch/)

```{.python .input  n=1}
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt


def readucr(filename):
    data = np.loadtxt(filename, delimiter="\t")
    y = data[:, 0]
    x = data[:, 1:]
    return x, y.astype(int)


root_url = "https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/"

x_train, y_train = readucr(root_url + "FordA_TRAIN.tsv")
x_test, y_test = readucr(root_url + "FordA_TEST.tsv")
x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))
x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))
num_classes = len(np.unique(y_train))
print("We have " + str(num_classes) + " classes")
idx = np.random.permutation(len(x_train))
x_train = x_train[idx]
y_train = y_train[idx]
y_train[y_train == -1] = 0
y_test[y_test == -1] = 0
```

```{.json .output n=1}
[
 {
  "name": "stdout",
  "output_type": "stream",
  "text": "We have 2 classes\n"
 }
]
```

Next we make the TCN model, we have a time series of length 500 in the dataset
so we must model the receptive field size of the network to be equal or more
than 500. We have two variables we can change to influence the receptive field
size, the kernel size and then the number of layers of the TCN.

We will work with a kernel size of 10 and 5 layers as that gives us a RFS = 1 +
(2^5-1)(10-1)*2 = 559 > 500.


```{.python .input  n=2}
from keras.models import Model
from keras.layers.core import Dense, Activation
from keras.layers.convolutional import Conv1D
from keras.layers import Dropout, Add, Lambda, Flatten, Input, BatchNormalization


def TCN(nb_classes,Chans=1, Samples=500, layers=5, kernel_s=10,filt=10, dropout=0,activation='elu'):
    regRate=.25
    input1 = Input(shape = (Samples, Chans))
    x1 = Conv1D(filt,kernel_size=kernel_s,dilation_rate=1,activation=activation, padding = 'causal',kernel_initializer='he_uniform')(input1)
    x1 = BatchNormalization()(x1)
    x1 = Dropout(dropout)(x1)
    x1 = Conv1D(filt,kernel_size=kernel_s,dilation_rate=1,activation=activation, padding = 'causal',kernel_initializer='he_uniform')(x1)
    x1 = BatchNormalization()(x1)
    x1 = Dropout(dropout)(x1)
    conv = Conv1D(filt,kernel_size=1,padding='same')(input1)
    added_1 = Add()([x1, conv])
    out = Activation(activation)(added_1)

    
    for i in range(layers-1):
        x = Conv1D(filt,kernel_size=kernel_s,dilation_rate=2**(i+1),activation=activation, padding = 'causal',kernel_initializer='he_uniform')(out)
        x = BatchNormalization()(x)
        x = Dropout(dropout)(x)
        x = Conv1D(filt,kernel_size=kernel_s,dilation_rate=2**(i+1),activation=activation, padding = 'causal',kernel_initializer='he_uniform')(x)
        x = BatchNormalization()(x)
        x = Dropout(dropout)(x)

        added = Add()([x, out])
        out = Activation(activation)(added)
    out = Lambda(lambda x: x[:,-1,:])(out)
    dense        = Dense(nb_classes, name = 'dense')(out)
    softmax      = Activation('softmax', name = 'softmax')(dense)
    
    return Model(inputs=input1,outputs=softmax)

TCN_model_1 = TCN(nb_classes = 2,filt=5)
TCN_model_1.summary()

```

```{.json .output n=2}
[
 {
  "name": "stdout",
  "output_type": "stream",
  "text": "Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 500, 1)]     0           []                               \n                                                                                                  \n conv1d (Conv1D)                (None, 500, 5)       55          ['input_1[0][0]']                \n                                                                                                  \n batch_normalization (BatchNorm  (None, 500, 5)      20          ['conv1d[0][0]']                 \n alization)                                                                                       \n                                                                                                  \n dropout (Dropout)              (None, 500, 5)       0           ['batch_normalization[0][0]']    \n                                                                                                  \n conv1d_1 (Conv1D)              (None, 500, 5)       255         ['dropout[0][0]']                \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 500, 5)      20          ['conv1d_1[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n dropout_1 (Dropout)            (None, 500, 5)       0           ['batch_normalization_1[0][0]']  \n                                                                                                  \n conv1d_2 (Conv1D)              (None, 500, 5)       10          ['input_1[0][0]']                \n                                                                                                  \n add (Add)                      (None, 500, 5)       0           ['dropout_1[0][0]',              \n                                                                  'conv1d_2[0][0]']               \n                                                                                                  \n activation (Activation)        (None, 500, 5)       0           ['add[0][0]']                    \n                                                                                                  \n conv1d_3 (Conv1D)              (None, 500, 5)       255         ['activation[0][0]']             \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 500, 5)      20          ['conv1d_3[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n dropout_2 (Dropout)            (None, 500, 5)       0           ['batch_normalization_2[0][0]']  \n                                                                                                  \n conv1d_4 (Conv1D)              (None, 500, 5)       255         ['dropout_2[0][0]']              \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 500, 5)      20          ['conv1d_4[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n dropout_3 (Dropout)            (None, 500, 5)       0           ['batch_normalization_3[0][0]']  \n                                                                                                  \n add_1 (Add)                    (None, 500, 5)       0           ['dropout_3[0][0]',              \n                                                                  'activation[0][0]']             \n                                                                                                  \n activation_1 (Activation)      (None, 500, 5)       0           ['add_1[0][0]']                  \n                                                                                                  \n conv1d_5 (Conv1D)              (None, 500, 5)       255         ['activation_1[0][0]']           \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 500, 5)      20          ['conv1d_5[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n dropout_4 (Dropout)            (None, 500, 5)       0           ['batch_normalization_4[0][0]']  \n                                                                                                  \n conv1d_6 (Conv1D)              (None, 500, 5)       255         ['dropout_4[0][0]']              \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 500, 5)      20          ['conv1d_6[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n dropout_5 (Dropout)            (None, 500, 5)       0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n add_2 (Add)                    (None, 500, 5)       0           ['dropout_5[0][0]',              \n                                                                  'activation_1[0][0]']           \n                                                                                                  \n activation_2 (Activation)      (None, 500, 5)       0           ['add_2[0][0]']                  \n                                                                                                  \n conv1d_7 (Conv1D)              (None, 500, 5)       255         ['activation_2[0][0]']           \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 500, 5)      20          ['conv1d_7[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n dropout_6 (Dropout)            (None, 500, 5)       0           ['batch_normalization_6[0][0]']  \n                                                                                                  \n conv1d_8 (Conv1D)              (None, 500, 5)       255         ['dropout_6[0][0]']              \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 500, 5)      20          ['conv1d_8[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n dropout_7 (Dropout)            (None, 500, 5)       0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n add_3 (Add)                    (None, 500, 5)       0           ['dropout_7[0][0]',              \n                                                                  'activation_2[0][0]']           \n                                                                                                  \n activation_3 (Activation)      (None, 500, 5)       0           ['add_3[0][0]']                  \n                                                                                                  \n conv1d_9 (Conv1D)              (None, 500, 5)       255         ['activation_3[0][0]']           \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 500, 5)      20          ['conv1d_9[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n dropout_8 (Dropout)            (None, 500, 5)       0           ['batch_normalization_8[0][0]']  \n                                                                                                  \n conv1d_10 (Conv1D)             (None, 500, 5)       255         ['dropout_8[0][0]']              \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 500, 5)      20          ['conv1d_10[0][0]']              \n rmalization)                                                                                     \n                                                                                                  \n dropout_9 (Dropout)            (None, 500, 5)       0           ['batch_normalization_9[0][0]']  \n                                                                                                  \n add_4 (Add)                    (None, 500, 5)       0           ['dropout_9[0][0]',              \n                                                                  'activation_3[0][0]']           \n                                                                                                  \n activation_4 (Activation)      (None, 500, 5)       0           ['add_4[0][0]']                  \n                                                                                                  \n lambda (Lambda)                (None, 5)            0           ['activation_4[0][0]']           \n                                                                                                  \n dense (Dense)                  (None, 2)            12          ['lambda[0][0]']                 \n                                                                                                  \n softmax (Activation)           (None, 2)            0           ['dense[0][0]']                  \n                                                                                                  \n==================================================================================================\nTotal params: 2,572\nTrainable params: 2,472\nNon-trainable params: 100\n__________________________________________________________________________________________________\n"
 }
]
```

While looking at the summary of the TCN we see that we have roughly 2372
trainable parameters, we can decrease and increase this number by increasing the
number of filters the network has. Let's first work with 5 filters and see how
well the network does.

We do the same proccedure as done in the Keras example, with learning rate
reduction and early stopping depending on validation loss.

```{.python .input  n=3}
epochs = 500
batch_size = 32

callbacks = [
    keras.callbacks.ModelCheckpoint(
        "best_model_1.h5", save_best_only=True, monitor="val_loss"
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor="val_loss", factor=0.5, patience=20, min_lr=0.0001
    ),
    keras.callbacks.EarlyStopping(monitor="val_loss", patience=50, verbose=1),
]
TCN_model_1.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["sparse_categorical_accuracy"],
)
history = TCN_model_1.fit(
    x_train,
    y_train,
    batch_size=batch_size,
    epochs=epochs,
    callbacks=callbacks,
    validation_split=0.2,
    verbose=1,
)
```

```{.json .output n=3}
[
 {
  "name": "stdout",
  "output_type": "stream",
  "text": "Epoch 1/500\n90/90 [==============================] - 11s 34ms/step - loss: 0.9717 - sparse_categorical_accuracy: 0.5448 - val_loss: 1.2359 - val_sparse_categorical_accuracy: 0.5520 - lr: 0.0010\nEpoch 2/500\n90/90 [==============================] - 2s 20ms/step - loss: 0.4918 - sparse_categorical_accuracy: 0.7351 - val_loss: 0.4279 - val_sparse_categorical_accuracy: 0.7961 - lr: 0.0010\nEpoch 3/500\n90/90 [==============================] - 2s 21ms/step - loss: 0.3400 - sparse_categorical_accuracy: 0.8604 - val_loss: 0.4122 - val_sparse_categorical_accuracy: 0.7864 - lr: 0.0010\nEpoch 4/500\n90/90 [==============================] - 1s 12ms/step - loss: 0.2839 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.2717 - val_sparse_categorical_accuracy: 0.8835 - lr: 0.0010\nEpoch 5/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.2476 - sparse_categorical_accuracy: 0.9062 - val_loss: 0.2536 - val_sparse_categorical_accuracy: 0.8863 - lr: 0.0010\nEpoch 6/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.2162 - sparse_categorical_accuracy: 0.9135 - val_loss: 0.2366 - val_sparse_categorical_accuracy: 0.9071 - lr: 0.0010\nEpoch 7/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.1986 - sparse_categorical_accuracy: 0.9240 - val_loss: 0.3842 - val_sparse_categorical_accuracy: 0.8336 - lr: 0.0010\nEpoch 8/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1970 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.2794 - val_sparse_categorical_accuracy: 0.8904 - lr: 0.0010\nEpoch 9/500\n90/90 [==============================] - 1s 12ms/step - loss: 0.1869 - sparse_categorical_accuracy: 0.9240 - val_loss: 0.1988 - val_sparse_categorical_accuracy: 0.9279 - lr: 0.0010\nEpoch 10/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1835 - sparse_categorical_accuracy: 0.9267 - val_loss: 0.2326 - val_sparse_categorical_accuracy: 0.9001 - lr: 0.0010\nEpoch 11/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.1794 - sparse_categorical_accuracy: 0.9323 - val_loss: 0.2173 - val_sparse_categorical_accuracy: 0.9168 - lr: 0.0010\nEpoch 12/500\n90/90 [==============================] - 1s 12ms/step - loss: 0.1654 - sparse_categorical_accuracy: 0.9337 - val_loss: 0.1764 - val_sparse_categorical_accuracy: 0.9362 - lr: 0.0010\nEpoch 13/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1584 - sparse_categorical_accuracy: 0.9413 - val_loss: 0.1750 - val_sparse_categorical_accuracy: 0.9307 - lr: 0.0010\nEpoch 14/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.1565 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.1992 - val_sparse_categorical_accuracy: 0.9168 - lr: 0.0010\nEpoch 15/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.1615 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1755 - val_sparse_categorical_accuracy: 0.9348 - lr: 0.0010\nEpoch 16/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1412 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1823 - val_sparse_categorical_accuracy: 0.9390 - lr: 0.0010\nEpoch 17/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1432 - sparse_categorical_accuracy: 0.9441 - val_loss: 0.1717 - val_sparse_categorical_accuracy: 0.9417 - lr: 0.0010\nEpoch 18/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.1354 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.1762 - val_sparse_categorical_accuracy: 0.9390 - lr: 0.0010\nEpoch 19/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.1410 - sparse_categorical_accuracy: 0.9431 - val_loss: 0.2740 - val_sparse_categorical_accuracy: 0.8932 - lr: 0.0010\nEpoch 20/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1378 - sparse_categorical_accuracy: 0.9507 - val_loss: 0.1701 - val_sparse_categorical_accuracy: 0.9390 - lr: 0.0010\nEpoch 21/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.1260 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.1852 - val_sparse_categorical_accuracy: 0.9334 - lr: 0.0010\nEpoch 22/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1253 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.1607 - val_sparse_categorical_accuracy: 0.9473 - lr: 0.0010\nEpoch 23/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1178 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.2113 - val_sparse_categorical_accuracy: 0.9112 - lr: 0.0010\nEpoch 24/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1159 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.2236 - val_sparse_categorical_accuracy: 0.9196 - lr: 0.0010\nEpoch 25/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1184 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.2414 - val_sparse_categorical_accuracy: 0.8988 - lr: 0.0010\nEpoch 26/500\n90/90 [==============================] - 1s 12ms/step - loss: 0.1107 - sparse_categorical_accuracy: 0.9590 - val_loss: 0.1591 - val_sparse_categorical_accuracy: 0.9390 - lr: 0.0010\nEpoch 27/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9660 - val_loss: 0.1837 - val_sparse_categorical_accuracy: 0.9334 - lr: 0.0010\nEpoch 28/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.3239 - val_sparse_categorical_accuracy: 0.8696 - lr: 0.0010\nEpoch 29/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1013 - sparse_categorical_accuracy: 0.9576 - val_loss: 0.2096 - val_sparse_categorical_accuracy: 0.9196 - lr: 0.0010\nEpoch 30/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0934 - sparse_categorical_accuracy: 0.9667 - val_loss: 0.1962 - val_sparse_categorical_accuracy: 0.9293 - lr: 0.0010\nEpoch 31/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0909 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.2964 - val_sparse_categorical_accuracy: 0.8932 - lr: 0.0010\nEpoch 32/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0758 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.2026 - val_sparse_categorical_accuracy: 0.9223 - lr: 0.0010\nEpoch 33/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0796 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.2081 - val_sparse_categorical_accuracy: 0.9196 - lr: 0.0010\nEpoch 34/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0787 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.2105 - val_sparse_categorical_accuracy: 0.9209 - lr: 0.0010\nEpoch 35/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0729 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.2151 - val_sparse_categorical_accuracy: 0.9279 - lr: 0.0010\nEpoch 36/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0653 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1987 - val_sparse_categorical_accuracy: 0.9209 - lr: 0.0010\nEpoch 37/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.2914 - val_sparse_categorical_accuracy: 0.9029 - lr: 0.0010\nEpoch 38/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0908 - sparse_categorical_accuracy: 0.9660 - val_loss: 0.2507 - val_sparse_categorical_accuracy: 0.9015 - lr: 0.0010\nEpoch 39/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.2209 - val_sparse_categorical_accuracy: 0.9140 - lr: 0.0010\nEpoch 40/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0590 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.2645 - val_sparse_categorical_accuracy: 0.9098 - lr: 0.0010\nEpoch 41/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9767 - val_loss: 0.2335 - val_sparse_categorical_accuracy: 0.9154 - lr: 0.0010\nEpoch 42/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.2530 - val_sparse_categorical_accuracy: 0.9126 - lr: 0.0010\nEpoch 43/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0580 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.2452 - val_sparse_categorical_accuracy: 0.9015 - lr: 0.0010\nEpoch 44/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0486 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.2654 - val_sparse_categorical_accuracy: 0.9112 - lr: 0.0010\nEpoch 45/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0534 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.2631 - val_sparse_categorical_accuracy: 0.9112 - lr: 0.0010\nEpoch 46/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.2714 - val_sparse_categorical_accuracy: 0.9154 - lr: 0.0010\nEpoch 47/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0477 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.2677 - val_sparse_categorical_accuracy: 0.9015 - lr: 5.0000e-04\nEpoch 48/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0396 - sparse_categorical_accuracy: 0.9854 - val_loss: 0.2757 - val_sparse_categorical_accuracy: 0.9085 - lr: 5.0000e-04\nEpoch 49/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0340 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.2726 - val_sparse_categorical_accuracy: 0.9085 - lr: 5.0000e-04\nEpoch 50/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0429 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.2937 - val_sparse_categorical_accuracy: 0.9154 - lr: 5.0000e-04\nEpoch 51/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0377 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.3136 - val_sparse_categorical_accuracy: 0.8974 - lr: 5.0000e-04\nEpoch 52/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0389 - sparse_categorical_accuracy: 0.9858 - val_loss: 0.2947 - val_sparse_categorical_accuracy: 0.9112 - lr: 5.0000e-04\nEpoch 53/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0313 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.2875 - val_sparse_categorical_accuracy: 0.9168 - lr: 5.0000e-04\nEpoch 54/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0363 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2955 - val_sparse_categorical_accuracy: 0.9154 - lr: 5.0000e-04\nEpoch 55/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.2884 - val_sparse_categorical_accuracy: 0.9098 - lr: 5.0000e-04\nEpoch 56/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.2833 - val_sparse_categorical_accuracy: 0.9112 - lr: 5.0000e-04\nEpoch 57/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0265 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.3043 - val_sparse_categorical_accuracy: 0.9085 - lr: 5.0000e-04\nEpoch 58/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.3091 - val_sparse_categorical_accuracy: 0.9043 - lr: 5.0000e-04\nEpoch 59/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.3190 - val_sparse_categorical_accuracy: 0.9043 - lr: 5.0000e-04\nEpoch 60/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0250 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.3475 - val_sparse_categorical_accuracy: 0.9001 - lr: 5.0000e-04\nEpoch 61/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0341 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.3021 - val_sparse_categorical_accuracy: 0.9098 - lr: 5.0000e-04\nEpoch 62/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0216 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.3185 - val_sparse_categorical_accuracy: 0.9154 - lr: 5.0000e-04\nEpoch 63/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0300 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.3113 - val_sparse_categorical_accuracy: 0.9071 - lr: 5.0000e-04\nEpoch 64/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0214 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.3153 - val_sparse_categorical_accuracy: 0.9071 - lr: 5.0000e-04\nEpoch 65/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.3392 - val_sparse_categorical_accuracy: 0.9085 - lr: 5.0000e-04\nEpoch 66/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0260 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.3157 - val_sparse_categorical_accuracy: 0.9140 - lr: 5.0000e-04\nEpoch 67/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.3271 - val_sparse_categorical_accuracy: 0.9140 - lr: 2.5000e-04\nEpoch 68/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.3323 - val_sparse_categorical_accuracy: 0.9140 - lr: 2.5000e-04\nEpoch 69/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0173 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.3470 - val_sparse_categorical_accuracy: 0.9043 - lr: 2.5000e-04\nEpoch 70/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.3312 - val_sparse_categorical_accuracy: 0.9098 - lr: 2.5000e-04\nEpoch 71/500\n90/90 [==============================] - 1s 13ms/step - loss: 0.0187 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.3522 - val_sparse_categorical_accuracy: 0.9029 - lr: 2.5000e-04\nEpoch 72/500\n90/90 [==============================] - 1s 13ms/step - loss: 0.0255 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.3590 - val_sparse_categorical_accuracy: 0.9098 - lr: 2.5000e-04\nEpoch 73/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.3305 - val_sparse_categorical_accuracy: 0.9223 - lr: 2.5000e-04\nEpoch 74/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0162 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.3392 - val_sparse_categorical_accuracy: 0.9098 - lr: 2.5000e-04\nEpoch 75/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0190 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.3368 - val_sparse_categorical_accuracy: 0.9085 - lr: 2.5000e-04\nEpoch 76/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0171 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.3364 - val_sparse_categorical_accuracy: 0.9043 - lr: 2.5000e-04\nEpoch 76: early stopping\n"
 }
]
```

We can see that our model does quite well, having a final validation accuracy of
around 91%, looking at the training and validation accuracy graph we can see
that it very quickly gets up to this 91% and then doesn't improve

```{.python .input  n=5}
metric = "sparse_categorical_accuracy"
plt.figure()
plt.plot(history.history[metric])
plt.plot(history.history["val_" + metric])
plt.title("model " + metric)
plt.ylabel(metric, fontsize="large")
plt.xlabel("epoch", fontsize="large")
plt.legend(["train", "val"], loc="best")
plt.show()
plt.close()
```

```{.json .output n=5}
[
 {
  "data": {
   "image/png": "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\n",
   "text/plain": "<Figure size 432x288 with 1 Axes>"
  },
  "metadata": {
   "needs_background": "light"
  },
  "output_type": "display_data"
 }
]
```

Lets try increasing the number of filters the network has to see if that
improves the performance.

```{.python .input  n=6}
TCN_model_2 = TCN(nb_classes = 2,filt=15)
TCN_model_2.summary()
epochs = 500
batch_size = 32

callbacks = [
    keras.callbacks.ModelCheckpoint(
        "best_model_2.h5", save_best_only=True, monitor="val_loss"
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor="val_loss", factor=0.5, patience=20, min_lr=0.0001
    ),
    keras.callbacks.EarlyStopping(monitor="val_loss", patience=50, verbose=1),
]
TCN_model_2.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["sparse_categorical_accuracy"],
)

```

```{.json .output n=6}
[
 {
  "name": "stdout",
  "output_type": "stream",
  "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_2 (InputLayer)           [(None, 500, 1)]     0           []                               \n                                                                                                  \n conv1d_11 (Conv1D)             (None, 500, 15)      165         ['input_2[0][0]']                \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 500, 15)     60          ['conv1d_11[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_10 (Dropout)           (None, 500, 15)      0           ['batch_normalization_10[0][0]'] \n                                                                                                  \n conv1d_12 (Conv1D)             (None, 500, 15)      2265        ['dropout_10[0][0]']             \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 500, 15)     60          ['conv1d_12[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_11 (Dropout)           (None, 500, 15)      0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n conv1d_13 (Conv1D)             (None, 500, 15)      30          ['input_2[0][0]']                \n                                                                                                  \n add_5 (Add)                    (None, 500, 15)      0           ['dropout_11[0][0]',             \n                                                                  'conv1d_13[0][0]']              \n                                                                                                  \n activation_5 (Activation)      (None, 500, 15)      0           ['add_5[0][0]']                  \n                                                                                                  \n conv1d_14 (Conv1D)             (None, 500, 15)      2265        ['activation_5[0][0]']           \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 500, 15)     60          ['conv1d_14[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_12 (Dropout)           (None, 500, 15)      0           ['batch_normalization_12[0][0]'] \n                                                                                                  \n conv1d_15 (Conv1D)             (None, 500, 15)      2265        ['dropout_12[0][0]']             \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 500, 15)     60          ['conv1d_15[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_13 (Dropout)           (None, 500, 15)      0           ['batch_normalization_13[0][0]'] \n                                                                                                  \n add_6 (Add)                    (None, 500, 15)      0           ['dropout_13[0][0]',             \n                                                                  'activation_5[0][0]']           \n                                                                                                  \n activation_6 (Activation)      (None, 500, 15)      0           ['add_6[0][0]']                  \n                                                                                                  \n conv1d_16 (Conv1D)             (None, 500, 15)      2265        ['activation_6[0][0]']           \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 500, 15)     60          ['conv1d_16[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_14 (Dropout)           (None, 500, 15)      0           ['batch_normalization_14[0][0]'] \n                                                                                                  \n conv1d_17 (Conv1D)             (None, 500, 15)      2265        ['dropout_14[0][0]']             \n                                                                                                  \n batch_normalization_15 (BatchN  (None, 500, 15)     60          ['conv1d_17[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_15 (Dropout)           (None, 500, 15)      0           ['batch_normalization_15[0][0]'] \n                                                                                                  \n add_7 (Add)                    (None, 500, 15)      0           ['dropout_15[0][0]',             \n                                                                  'activation_6[0][0]']           \n                                                                                                  \n activation_7 (Activation)      (None, 500, 15)      0           ['add_7[0][0]']                  \n                                                                                                  \n conv1d_18 (Conv1D)             (None, 500, 15)      2265        ['activation_7[0][0]']           \n                                                                                                  \n batch_normalization_16 (BatchN  (None, 500, 15)     60          ['conv1d_18[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_16 (Dropout)           (None, 500, 15)      0           ['batch_normalization_16[0][0]'] \n                                                                                                  \n conv1d_19 (Conv1D)             (None, 500, 15)      2265        ['dropout_16[0][0]']             \n                                                                                                  \n batch_normalization_17 (BatchN  (None, 500, 15)     60          ['conv1d_19[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_17 (Dropout)           (None, 500, 15)      0           ['batch_normalization_17[0][0]'] \n                                                                                                  \n add_8 (Add)                    (None, 500, 15)      0           ['dropout_17[0][0]',             \n                                                                  'activation_7[0][0]']           \n                                                                                                  \n activation_8 (Activation)      (None, 500, 15)      0           ['add_8[0][0]']                  \n                                                                                                  \n conv1d_20 (Conv1D)             (None, 500, 15)      2265        ['activation_8[0][0]']           \n                                                                                                  \n batch_normalization_18 (BatchN  (None, 500, 15)     60          ['conv1d_20[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_18 (Dropout)           (None, 500, 15)      0           ['batch_normalization_18[0][0]'] \n                                                                                                  \n conv1d_21 (Conv1D)             (None, 500, 15)      2265        ['dropout_18[0][0]']             \n                                                                                                  \n batch_normalization_19 (BatchN  (None, 500, 15)     60          ['conv1d_21[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_19 (Dropout)           (None, 500, 15)      0           ['batch_normalization_19[0][0]'] \n                                                                                                  \n add_9 (Add)                    (None, 500, 15)      0           ['dropout_19[0][0]',             \n                                                                  'activation_8[0][0]']           \n                                                                                                  \n activation_9 (Activation)      (None, 500, 15)      0           ['add_9[0][0]']                  \n                                                                                                  \n lambda_1 (Lambda)              (None, 15)           0           ['activation_9[0][0]']           \n                                                                                                  \n dense (Dense)                  (None, 2)            32          ['lambda_1[0][0]']               \n                                                                                                  \n softmax (Activation)           (None, 2)            0           ['dense[0][0]']                  \n                                                                                                  \n==================================================================================================\nTotal params: 21,212\nTrainable params: 20,912\nNon-trainable params: 300\n__________________________________________________________________________________________________\n"
 }
]
```

```{.python .input  n=7}
history = TCN_model_2.fit(
    x_train,
    y_train,
    batch_size=batch_size,
    epochs=epochs,
    callbacks=callbacks,
    validation_split=0.2,
    verbose=1,
)
```

```{.json .output n=7}
[
 {
  "name": "stdout",
  "output_type": "stream",
  "text": "Epoch 1/500\n90/90 [==============================] - 5s 20ms/step - loss: 0.7026 - sparse_categorical_accuracy: 0.6823 - val_loss: 2.2428 - val_sparse_categorical_accuracy: 0.5368 - lr: 0.0010\nEpoch 2/500\n90/90 [==============================] - 1s 12ms/step - loss: 0.2933 - sparse_categorical_accuracy: 0.8691 - val_loss: 0.5623 - val_sparse_categorical_accuracy: 0.7933 - lr: 0.0010\nEpoch 3/500\n90/90 [==============================] - 1s 14ms/step - loss: 0.2257 - sparse_categorical_accuracy: 0.9080 - val_loss: 0.3179 - val_sparse_categorical_accuracy: 0.8682 - lr: 0.0010\nEpoch 4/500\n90/90 [==============================] - 1s 17ms/step - loss: 0.1778 - sparse_categorical_accuracy: 0.9260 - val_loss: 0.1919 - val_sparse_categorical_accuracy: 0.9071 - lr: 0.0010\nEpoch 5/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1535 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.2212 - val_sparse_categorical_accuracy: 0.9015 - lr: 0.0010\nEpoch 6/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1351 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.2222 - val_sparse_categorical_accuracy: 0.9029 - lr: 0.0010\nEpoch 7/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1016 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.2292 - val_sparse_categorical_accuracy: 0.9029 - lr: 0.0010\nEpoch 8/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1056 - sparse_categorical_accuracy: 0.9601 - val_loss: 0.2194 - val_sparse_categorical_accuracy: 0.9015 - lr: 0.0010\nEpoch 9/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0770 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2100 - val_sparse_categorical_accuracy: 0.9043 - lr: 0.0010\nEpoch 10/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0673 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.2207 - val_sparse_categorical_accuracy: 0.9015 - lr: 0.0010\nEpoch 11/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0683 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.4673 - val_sparse_categorical_accuracy: 0.8530 - lr: 0.0010\nEpoch 12/500\n90/90 [==============================] - 1s 12ms/step - loss: 0.0579 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.2410 - val_sparse_categorical_accuracy: 0.9015 - lr: 0.0010\nEpoch 13/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0393 - sparse_categorical_accuracy: 0.9885 - val_loss: 0.2252 - val_sparse_categorical_accuracy: 0.9057 - lr: 0.0010\nEpoch 14/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.3696 - val_sparse_categorical_accuracy: 0.8835 - lr: 0.0010\nEpoch 15/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0310 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.3575 - val_sparse_categorical_accuracy: 0.8835 - lr: 0.0010\nEpoch 16/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0279 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.2712 - val_sparse_categorical_accuracy: 0.9057 - lr: 0.0010\nEpoch 17/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0322 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.2862 - val_sparse_categorical_accuracy: 0.8946 - lr: 0.0010\nEpoch 18/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0186 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.2878 - val_sparse_categorical_accuracy: 0.9043 - lr: 0.0010\nEpoch 19/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0209 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.2709 - val_sparse_categorical_accuracy: 0.9071 - lr: 0.0010\nEpoch 20/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0344 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.3604 - val_sparse_categorical_accuracy: 0.8890 - lr: 0.0010\nEpoch 21/500\n90/90 [==============================] - 1s 12ms/step - loss: 0.0341 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.3389 - val_sparse_categorical_accuracy: 0.8918 - lr: 0.0010\nEpoch 22/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0139 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.3452 - val_sparse_categorical_accuracy: 0.9029 - lr: 0.0010\nEpoch 23/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0109 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.3448 - val_sparse_categorical_accuracy: 0.9043 - lr: 0.0010\nEpoch 24/500\n90/90 [==============================] - 1s 12ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.3958 - val_sparse_categorical_accuracy: 0.8877 - lr: 0.0010\nEpoch 25/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.2737 - val_sparse_categorical_accuracy: 0.9112 - lr: 5.0000e-04\nEpoch 26/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2896 - val_sparse_categorical_accuracy: 0.9112 - lr: 5.0000e-04\nEpoch 27/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2763 - val_sparse_categorical_accuracy: 0.9098 - lr: 5.0000e-04\nEpoch 28/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0030 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2728 - val_sparse_categorical_accuracy: 0.9112 - lr: 5.0000e-04\nEpoch 29/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2767 - val_sparse_categorical_accuracy: 0.9140 - lr: 5.0000e-04\nEpoch 30/500\n90/90 [==============================] - 1s 12ms/step - loss: 0.0025 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2964 - val_sparse_categorical_accuracy: 0.8988 - lr: 5.0000e-04\nEpoch 31/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2838 - val_sparse_categorical_accuracy: 0.9112 - lr: 5.0000e-04\nEpoch 32/500\n90/90 [==============================] - 1s 12ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.2889 - val_sparse_categorical_accuracy: 0.9154 - lr: 5.0000e-04\nEpoch 33/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0020 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2818 - val_sparse_categorical_accuracy: 0.9126 - lr: 5.0000e-04\nEpoch 34/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0021 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3045 - val_sparse_categorical_accuracy: 0.9098 - lr: 5.0000e-04\nEpoch 35/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0018 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3019 - val_sparse_categorical_accuracy: 0.9001 - lr: 5.0000e-04\nEpoch 36/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.2918 - val_sparse_categorical_accuracy: 0.9126 - lr: 5.0000e-04\nEpoch 37/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.2996 - val_sparse_categorical_accuracy: 0.9071 - lr: 5.0000e-04\nEpoch 38/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0019 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2858 - val_sparse_categorical_accuracy: 0.9140 - lr: 5.0000e-04\nEpoch 39/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0013 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2985 - val_sparse_categorical_accuracy: 0.9112 - lr: 5.0000e-04\nEpoch 40/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0010 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3036 - val_sparse_categorical_accuracy: 0.9126 - lr: 5.0000e-04\nEpoch 41/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.4849 - val_sparse_categorical_accuracy: 0.8835 - lr: 5.0000e-04\nEpoch 42/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.3850 - val_sparse_categorical_accuracy: 0.9057 - lr: 5.0000e-04\nEpoch 43/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.3593 - val_sparse_categorical_accuracy: 0.8974 - lr: 5.0000e-04\nEpoch 44/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.4029 - val_sparse_categorical_accuracy: 0.9071 - lr: 5.0000e-04\nEpoch 45/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0023 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3584 - val_sparse_categorical_accuracy: 0.9029 - lr: 2.5000e-04\nEpoch 46/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3535 - val_sparse_categorical_accuracy: 0.9043 - lr: 2.5000e-04\nEpoch 47/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.3562 - val_sparse_categorical_accuracy: 0.9085 - lr: 2.5000e-04\nEpoch 48/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3590 - val_sparse_categorical_accuracy: 0.9098 - lr: 2.5000e-04\nEpoch 49/500\n90/90 [==============================] - 1s 11ms/step - loss: 7.9658e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3499 - val_sparse_categorical_accuracy: 0.9085 - lr: 2.5000e-04\nEpoch 50/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.3977 - val_sparse_categorical_accuracy: 0.8904 - lr: 2.5000e-04\nEpoch 51/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.3606 - val_sparse_categorical_accuracy: 0.9015 - lr: 2.5000e-04\nEpoch 52/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.3612 - val_sparse_categorical_accuracy: 0.9071 - lr: 2.5000e-04\nEpoch 53/500\n90/90 [==============================] - 1s 11ms/step - loss: 9.6241e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3539 - val_sparse_categorical_accuracy: 0.9071 - lr: 2.5000e-04\nEpoch 54/500\n90/90 [==============================] - 1s 12ms/step - loss: 8.3294e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3502 - val_sparse_categorical_accuracy: 0.9071 - lr: 2.5000e-04\nEpoch 54: early stopping\n"
 }
]
```

```{.python .input  n=9}
metric = "sparse_categorical_accuracy"
plt.figure()
plt.plot(history.history[metric])
plt.plot(history.history["val_" + metric])
plt.title("model " + metric)
plt.ylabel(metric, fontsize="large")
plt.xlabel("epoch", fontsize="large")
plt.legend(["train", "val"], loc="best")
plt.show()
plt.close()
```

```{.json .output n=9}
[
 {
  "data": {
   "image/png": "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\n",
   "text/plain": "<Figure size 432x288 with 1 Axes>"
  },
  "metadata": {
   "needs_background": "light"
  },
  "output_type": "display_data"
 }
]
```

Another trick we can try is to change the source code of the TCN model and
instead of only looking at the last sample of each filter (the out layer) we
instead flatten the network, this increases the number of parameters in network
so let's again decrease the number of filters we use.

```{.python .input  n=10}
def TCN(nb_classes,Chans=1, Samples=500, layers=5, kernel_s=10,filt=10, dropout=0,activation='elu'):
    regRate=.25
    input1 = Input(shape = (Samples, Chans))
    x1 = Conv1D(filt,kernel_size=kernel_s,dilation_rate=1,activation=activation, padding = 'causal',kernel_initializer='he_uniform')(input1)
    x1 = BatchNormalization()(x1)
    x1 = Dropout(dropout)(x1)
    x1 = Conv1D(filt,kernel_size=kernel_s,dilation_rate=1,activation=activation, padding = 'causal',kernel_initializer='he_uniform')(x1)
    x1 = BatchNormalization()(x1)
    x1 = Dropout(dropout)(x1)
    conv = Conv1D(filt,kernel_size=1,padding='same')(input1)
    added_1 = Add()([x1, conv])
    out = Activation(activation)(added_1)

    
    for i in range(layers-1):
        x = Conv1D(filt,kernel_size=kernel_s,dilation_rate=2**(i+1),activation=activation, padding = 'causal',kernel_initializer='he_uniform')(out)
        x = BatchNormalization()(x)
        x = Dropout(dropout)(x)
        x = Conv1D(filt,kernel_size=kernel_s,dilation_rate=2**(i+1),activation=activation, padding = 'causal',kernel_initializer='he_uniform')(x)
        x = BatchNormalization()(x)
        x = Dropout(dropout)(x)

        added = Add()([x, out])
        out = Activation(activation)(added)
    out = Flatten()(out)
    dense        = Dense(nb_classes, name = 'dense')(out)
    softmax      = Activation('softmax', name = 'softmax')(dense)
    
    return Model(inputs=input1,outputs=softmax)

TCN_model_3 = TCN(nb_classes = 2,filt=5)
TCN_model_3.summary()
```

```{.json .output n=10}
[
 {
  "name": "stdout",
  "output_type": "stream",
  "text": "Model: \"model_2\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None, 500, 1)]     0           []                               \n                                                                                                  \n conv1d_22 (Conv1D)             (None, 500, 5)       55          ['input_3[0][0]']                \n                                                                                                  \n batch_normalization_20 (BatchN  (None, 500, 5)      20          ['conv1d_22[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_20 (Dropout)           (None, 500, 5)       0           ['batch_normalization_20[0][0]'] \n                                                                                                  \n conv1d_23 (Conv1D)             (None, 500, 5)       255         ['dropout_20[0][0]']             \n                                                                                                  \n batch_normalization_21 (BatchN  (None, 500, 5)      20          ['conv1d_23[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_21 (Dropout)           (None, 500, 5)       0           ['batch_normalization_21[0][0]'] \n                                                                                                  \n conv1d_24 (Conv1D)             (None, 500, 5)       10          ['input_3[0][0]']                \n                                                                                                  \n add_10 (Add)                   (None, 500, 5)       0           ['dropout_21[0][0]',             \n                                                                  'conv1d_24[0][0]']              \n                                                                                                  \n activation_10 (Activation)     (None, 500, 5)       0           ['add_10[0][0]']                 \n                                                                                                  \n conv1d_25 (Conv1D)             (None, 500, 5)       255         ['activation_10[0][0]']          \n                                                                                                  \n batch_normalization_22 (BatchN  (None, 500, 5)      20          ['conv1d_25[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_22 (Dropout)           (None, 500, 5)       0           ['batch_normalization_22[0][0]'] \n                                                                                                  \n conv1d_26 (Conv1D)             (None, 500, 5)       255         ['dropout_22[0][0]']             \n                                                                                                  \n batch_normalization_23 (BatchN  (None, 500, 5)      20          ['conv1d_26[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_23 (Dropout)           (None, 500, 5)       0           ['batch_normalization_23[0][0]'] \n                                                                                                  \n add_11 (Add)                   (None, 500, 5)       0           ['dropout_23[0][0]',             \n                                                                  'activation_10[0][0]']          \n                                                                                                  \n activation_11 (Activation)     (None, 500, 5)       0           ['add_11[0][0]']                 \n                                                                                                  \n conv1d_27 (Conv1D)             (None, 500, 5)       255         ['activation_11[0][0]']          \n                                                                                                  \n batch_normalization_24 (BatchN  (None, 500, 5)      20          ['conv1d_27[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_24 (Dropout)           (None, 500, 5)       0           ['batch_normalization_24[0][0]'] \n                                                                                                  \n conv1d_28 (Conv1D)             (None, 500, 5)       255         ['dropout_24[0][0]']             \n                                                                                                  \n batch_normalization_25 (BatchN  (None, 500, 5)      20          ['conv1d_28[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_25 (Dropout)           (None, 500, 5)       0           ['batch_normalization_25[0][0]'] \n                                                                                                  \n add_12 (Add)                   (None, 500, 5)       0           ['dropout_25[0][0]',             \n                                                                  'activation_11[0][0]']          \n                                                                                                  \n activation_12 (Activation)     (None, 500, 5)       0           ['add_12[0][0]']                 \n                                                                                                  \n conv1d_29 (Conv1D)             (None, 500, 5)       255         ['activation_12[0][0]']          \n                                                                                                  \n batch_normalization_26 (BatchN  (None, 500, 5)      20          ['conv1d_29[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_26 (Dropout)           (None, 500, 5)       0           ['batch_normalization_26[0][0]'] \n                                                                                                  \n conv1d_30 (Conv1D)             (None, 500, 5)       255         ['dropout_26[0][0]']             \n                                                                                                  \n batch_normalization_27 (BatchN  (None, 500, 5)      20          ['conv1d_30[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_27 (Dropout)           (None, 500, 5)       0           ['batch_normalization_27[0][0]'] \n                                                                                                  \n add_13 (Add)                   (None, 500, 5)       0           ['dropout_27[0][0]',             \n                                                                  'activation_12[0][0]']          \n                                                                                                  \n activation_13 (Activation)     (None, 500, 5)       0           ['add_13[0][0]']                 \n                                                                                                  \n conv1d_31 (Conv1D)             (None, 500, 5)       255         ['activation_13[0][0]']          \n                                                                                                  \n batch_normalization_28 (BatchN  (None, 500, 5)      20          ['conv1d_31[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_28 (Dropout)           (None, 500, 5)       0           ['batch_normalization_28[0][0]'] \n                                                                                                  \n conv1d_32 (Conv1D)             (None, 500, 5)       255         ['dropout_28[0][0]']             \n                                                                                                  \n batch_normalization_29 (BatchN  (None, 500, 5)      20          ['conv1d_32[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n dropout_29 (Dropout)           (None, 500, 5)       0           ['batch_normalization_29[0][0]'] \n                                                                                                  \n add_14 (Add)                   (None, 500, 5)       0           ['dropout_29[0][0]',             \n                                                                  'activation_13[0][0]']          \n                                                                                                  \n activation_14 (Activation)     (None, 500, 5)       0           ['add_14[0][0]']                 \n                                                                                                  \n flatten (Flatten)              (None, 2500)         0           ['activation_14[0][0]']          \n                                                                                                  \n dense (Dense)                  (None, 2)            5002        ['flatten[0][0]']                \n                                                                                                  \n softmax (Activation)           (None, 2)            0           ['dense[0][0]']                  \n                                                                                                  \n==================================================================================================\nTotal params: 7,562\nTrainable params: 7,462\nNon-trainable params: 100\n__________________________________________________________________________________________________\n"
 }
]
```

```{.python .input  n=11}
epochs = 500
batch_size = 32

callbacks = [
    keras.callbacks.ModelCheckpoint(
        "best_model_3.h5", save_best_only=True, monitor="val_loss"
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor="val_loss", factor=0.5, patience=20, min_lr=0.0001
    ),
    keras.callbacks.EarlyStopping(monitor="val_loss", patience=50, verbose=1),
]
TCN_model_3.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["sparse_categorical_accuracy"],
)
history = TCN_model_3.fit(
    x_train,
    y_train,
    batch_size=batch_size,
    epochs=epochs,
    callbacks=callbacks,
    validation_split=0.2,
    verbose=1,
)
```

```{.json .output n=11}
[
 {
  "name": "stdout",
  "output_type": "stream",
  "text": "Epoch 1/500\n90/90 [==============================] - 4s 18ms/step - loss: 0.8511 - sparse_categorical_accuracy: 0.6469 - val_loss: 3.3143 - val_sparse_categorical_accuracy: 0.5007 - lr: 0.0010\nEpoch 2/500\n90/90 [==============================] - 1s 12ms/step - loss: 0.3462 - sparse_categorical_accuracy: 0.8677 - val_loss: 0.5212 - val_sparse_categorical_accuracy: 0.8114 - lr: 0.0010\nEpoch 3/500\n90/90 [==============================] - 1s 12ms/step - loss: 0.2373 - sparse_categorical_accuracy: 0.9125 - val_loss: 0.2840 - val_sparse_categorical_accuracy: 0.8793 - lr: 0.0010\nEpoch 4/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.2195 - sparse_categorical_accuracy: 0.9146 - val_loss: 0.3031 - val_sparse_categorical_accuracy: 0.8974 - lr: 0.0010\nEpoch 5/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.2022 - sparse_categorical_accuracy: 0.9233 - val_loss: 0.3261 - val_sparse_categorical_accuracy: 0.8863 - lr: 0.0010\nEpoch 6/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1752 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.5190 - val_sparse_categorical_accuracy: 0.8363 - lr: 0.0010\nEpoch 7/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.1465 - sparse_categorical_accuracy: 0.9410 - val_loss: 0.3399 - val_sparse_categorical_accuracy: 0.8807 - lr: 0.0010\nEpoch 8/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.1204 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.3331 - val_sparse_categorical_accuracy: 0.8863 - lr: 0.0010\nEpoch 9/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1204 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.3068 - val_sparse_categorical_accuracy: 0.8988 - lr: 0.0010\nEpoch 10/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1112 - sparse_categorical_accuracy: 0.9573 - val_loss: 0.4133 - val_sparse_categorical_accuracy: 0.8585 - lr: 0.0010\nEpoch 11/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.1313 - sparse_categorical_accuracy: 0.9503 - val_loss: 0.8094 - val_sparse_categorical_accuracy: 0.8239 - lr: 0.0010\nEpoch 12/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.1284 - sparse_categorical_accuracy: 0.9510 - val_loss: 0.3401 - val_sparse_categorical_accuracy: 0.8863 - lr: 0.0010\nEpoch 13/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0947 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.3506 - val_sparse_categorical_accuracy: 0.8918 - lr: 0.0010\nEpoch 14/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0781 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.3986 - val_sparse_categorical_accuracy: 0.8821 - lr: 0.0010\nEpoch 15/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.3956 - val_sparse_categorical_accuracy: 0.8835 - lr: 0.0010\nEpoch 16/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9649 - val_loss: 0.4759 - val_sparse_categorical_accuracy: 0.8724 - lr: 0.0010\nEpoch 17/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0737 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.4114 - val_sparse_categorical_accuracy: 0.8807 - lr: 0.0010\nEpoch 18/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0814 - sparse_categorical_accuracy: 0.9670 - val_loss: 0.4156 - val_sparse_categorical_accuracy: 0.8988 - lr: 0.0010\nEpoch 19/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0514 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.3724 - val_sparse_categorical_accuracy: 0.8932 - lr: 0.0010\nEpoch 20/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0544 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.4212 - val_sparse_categorical_accuracy: 0.8918 - lr: 0.0010\nEpoch 21/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0449 - sparse_categorical_accuracy: 0.9858 - val_loss: 0.4394 - val_sparse_categorical_accuracy: 0.8779 - lr: 0.0010\nEpoch 22/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.4151 - val_sparse_categorical_accuracy: 0.8849 - lr: 0.0010\nEpoch 23/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0578 - sparse_categorical_accuracy: 0.9812 - val_loss: 0.4482 - val_sparse_categorical_accuracy: 0.8904 - lr: 0.0010\nEpoch 24/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.4182 - val_sparse_categorical_accuracy: 0.8932 - lr: 5.0000e-04\nEpoch 25/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0209 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.4111 - val_sparse_categorical_accuracy: 0.8946 - lr: 5.0000e-04\nEpoch 26/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0191 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.3970 - val_sparse_categorical_accuracy: 0.9001 - lr: 5.0000e-04\nEpoch 27/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0156 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.4019 - val_sparse_categorical_accuracy: 0.8974 - lr: 5.0000e-04\nEpoch 28/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.4273 - val_sparse_categorical_accuracy: 0.8904 - lr: 5.0000e-04\nEpoch 29/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0168 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.4179 - val_sparse_categorical_accuracy: 0.8988 - lr: 5.0000e-04\nEpoch 30/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.4302 - val_sparse_categorical_accuracy: 0.8946 - lr: 5.0000e-04\nEpoch 31/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.4508 - val_sparse_categorical_accuracy: 0.8932 - lr: 5.0000e-04\nEpoch 32/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0157 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.4591 - val_sparse_categorical_accuracy: 0.8807 - lr: 5.0000e-04\nEpoch 33/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0170 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.4427 - val_sparse_categorical_accuracy: 0.8807 - lr: 5.0000e-04\nEpoch 34/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0148 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.5704 - val_sparse_categorical_accuracy: 0.8738 - lr: 5.0000e-04\nEpoch 35/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0142 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.4625 - val_sparse_categorical_accuracy: 0.8960 - lr: 5.0000e-04\nEpoch 36/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0128 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.5169 - val_sparse_categorical_accuracy: 0.8890 - lr: 5.0000e-04\nEpoch 37/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.4603 - val_sparse_categorical_accuracy: 0.8974 - lr: 5.0000e-04\nEpoch 38/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0153 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.4560 - val_sparse_categorical_accuracy: 0.8988 - lr: 5.0000e-04\nEpoch 39/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0132 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.5157 - val_sparse_categorical_accuracy: 0.8738 - lr: 5.0000e-04\nEpoch 40/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.5172 - val_sparse_categorical_accuracy: 0.8918 - lr: 5.0000e-04\nEpoch 41/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.4915 - val_sparse_categorical_accuracy: 0.8877 - lr: 5.0000e-04\nEpoch 42/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.4898 - val_sparse_categorical_accuracy: 0.8904 - lr: 5.0000e-04\nEpoch 43/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0122 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.4642 - val_sparse_categorical_accuracy: 0.8946 - lr: 5.0000e-04\nEpoch 44/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.4602 - val_sparse_categorical_accuracy: 0.8835 - lr: 2.5000e-04\nEpoch 45/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.4580 - val_sparse_categorical_accuracy: 0.8932 - lr: 2.5000e-04\nEpoch 46/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.4703 - val_sparse_categorical_accuracy: 0.8863 - lr: 2.5000e-04\nEpoch 47/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.4532 - val_sparse_categorical_accuracy: 0.9001 - lr: 2.5000e-04\nEpoch 48/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.4753 - val_sparse_categorical_accuracy: 0.8932 - lr: 2.5000e-04\nEpoch 49/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.4990 - val_sparse_categorical_accuracy: 0.8890 - lr: 2.5000e-04\nEpoch 50/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.4871 - val_sparse_categorical_accuracy: 0.8877 - lr: 2.5000e-04\nEpoch 51/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.4996 - val_sparse_categorical_accuracy: 0.8904 - lr: 2.5000e-04\nEpoch 52/500\n90/90 [==============================] - 1s 11ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.5458 - val_sparse_categorical_accuracy: 0.8793 - lr: 2.5000e-04\nEpoch 53/500\n90/90 [==============================] - 1s 10ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.4834 - val_sparse_categorical_accuracy: 0.8877 - lr: 2.5000e-04\nEpoch 53: early stopping\n"
 }
]
```

```{.python .input  n=13}
metric = "sparse_categorical_accuracy"
plt.figure()
plt.plot(history.history[metric])
plt.plot(history.history["val_" + metric])
plt.title("model " + metric)
plt.ylabel(metric, fontsize="large")
plt.xlabel("epoch", fontsize="large")
plt.legend(["train", "val"], loc="best")
plt.show()
plt.close()
```

```{.json .output n=13}
[
 {
  "data": {
   "image/png": "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\n",
   "text/plain": "<Figure size 432x288 with 1 Axes>"
  },
  "metadata": {
   "needs_background": "light"
  },
  "output_type": "display_data"
 }
]
```

But as always, the best thing is to do cross validated hyperparameter search to
see how many filters you need to get a good performing network, for our case I
believe that the second network we tested was the best one so let's look at the
final test accuracy of that network:


```{.python .input  n=14}
TCN_model_2 = keras.models.load_model("best_model_2.h5")

test_loss, test_acc = TCN_model_2.evaluate(x_test, y_test)

print("Test accuracy", test_acc)
print("Test loss", test_loss)
```

```{.json .output n=14}
[
 {
  "name": "stdout",
  "output_type": "stream",
  "text": "42/42 [==============================] - 1s 6ms/step - loss: 0.2183 - sparse_categorical_accuracy: 0.9182\nTest accuracy 0.918181836605072\nTest loss 0.21826055645942688\n"
 }
]
```